\section{Matrices \& Vectors}
\begin{mainbox}{General}
$m$x$n$ Matrices have m rows and n columns.\\
The element $(i,j)$ can be denoted as $a_{i,j}$ or $(A)_{i,j}$
\smallskip\\
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rll}
	\textcolor{blue}{T 2.1} & \multicolumn{1}{l|}{$(\alpha\beta)A = \alpha(\beta A)$} & $(A+B)+C = A+(B+C)$ \\
	& \multicolumn{1}{l|}{$(\alpha A)B = \alpha(AB)$} & $(AB)\cdot C = A\cdot (BC)$ \\
	& \multicolumn{1}{l|}{$(\alpha + \beta)\cdot A = \alpha A + \beta A$} & $(A+B)\cdot C = AC + BC$ \\
	& \multicolumn{1}{l|}{$\alpha (A+B) = \alpha A + \alpha B$} & $A\cdot (B+C) = AB+AC$ \\
	& \multicolumn{1}{l|}{$A+B = B+A$} & \\
	\multicolumn{3}{c}{\danger in general$AB \neq BA$}\\
	\multicolumn{3}{c}{If $AB = BA$ we say «A and B commute»}\\
	\rule{0pt}{3ex}
	Def. & \multicolumn{2}{l}{If $AB = O$, we call $A$ and $B$ \textcolor{blue}{divisors of zero}.}\\
	\rule{0pt}{3ex}
	Def. & \multicolumn{2}{l}{A \textcolor{blue}{linear combination} of vectors $a_1 ... a_n$ is an}\\
 	& \multicolumn{2}{l}{expression of the following type:}\\
 	& \multicolumn{2}{l}{$\alpha_n\cdot a_n + ... + \alpha_1\cdot a_1$}\\
 	\rule{0pt}{3ex}
	Def. & \multicolumn{2}{l}{A matrix is \textcolor{blue}{symmetric} when $A^T = A$ and}\\
	& \multicolumn{2}{l}{\textcolor{blue}{Hermitian} when $A^H = A$ (real diagonal).}\\
	\rule{0pt}{3ex}
	Def. & \multicolumn{2}{l}{A matrix is \textcolor{blue}{skew-symmetric} when $A^T = -A$.}\\
	& \multicolumn{2}{l}{(zeros on diagonal)}\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.6} & \multicolumn{2}{l}{$(A^T)^T = A$ \qquad\qquad $\:(\alpha A)^T = \alpha(A^T)$}\\
	& \multicolumn{2}{l}{$(AB)^T = B^TA^T$ \qquad $(A+B)^T = A^T + B^T$}\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.7} & \multicolumn{2}{l}{If A, B symmetric: $AB = BA \Leftrightarrow AB$ symmetric}\\
	& \multicolumn{2}{l}{For any A: $A^TA = AA^T$ (symmetric)}\\
\end{tabular}
\end{mainbox}

\begin{mainbox}{Scalar Product and Norm}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rll}
	Def. & \textcolor{red}{Eucl. scalar product} (SP):& $\langle x,y\rangle :\equiv x^Hy$\\
	& (inner product) & \\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.9} & linearity in second factor: & $\langle x,y+z\rangle = \langle x,y\rangle + \langle x,z\rangle$\\
	& & $\langle x,\alpha y\rangle = \alpha \langle x,y\rangle$\\
	& symmetric / hermitian: & $\langle x,y\rangle = \compconj{\langle y,x \rangle}$\\
	& positive definite: & $\langle x,x\rangle \geq 0$; if $\;'='\;\Rightarrow\;x = 0$\\ 
	\rule{0pt}{3ex}
	\textcolor{blue}{C 2.10} & bilinearity in $\mathbb{R}^n$: & $\langle w+x,y\rangle = \langle w,y\rangle + \langle x,y\rangle$\\
	& & $\langle \alpha x,y\rangle = \alpha \langle x,y\rangle$\\
	& sesquilinearity in $\mathbb{C}^n$: & $\langle w+x,y\rangle = \langle w,y\rangle + \langle x,y\rangle$\\
	& & $\langle \alpha x,y\rangle = \compconj{\alpha} \langle x,y\rangle$\\ 
	\rule{0pt}{3ex}
	Def. & \textcolor{red}{Eucl. norm / 2-norm}: & $||x|| :\equiv \sqrt{\langle x,x \rangle}$\\
	\rule{0pt}{3ex}
\end{tabular}
\textcolor{blue}{(Cauchy-)Schwarz inequality (CBS inequality)} \\
\begin{tabular}{l}
	$|\langle x,y\rangle| \leq ||x|| \cdot ||y||$\\
	The equality holds iff y is a multiple of x or vice versa\\
\end{tabular}\\
\smallskip\\
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rrl}
	\textcolor{blue}{T 2.12} & \multicolumn{2}{l}{The following holds for the 2-norm:} \\
	& (N1) & positive definite: $||x|| \geq 0$, if$\;'='\;\Rightarrow\; x = 0$\\
	& (N2) & $||\alpha x|| = |\alpha |\;||x||$\\
	& (N3) & \textcolor{red}{triangle inequality}: $||x\pm y|| \leq ||x|| + ||y||$\\
	\rule{0pt}{3ex}
	Def. & \multicolumn{2}{l}{angle $\varphi$ between x and y: $\varphi = arc\;cos\left(\frac{\langle x,y\rangle}{||x||\cdot ||y||}\right)$}\\
	\rule{0pt}{3ex}
	Def. & \multicolumn{2}{l}{x and y are \textcolor{blue}{orthogonal}, if $\langle x,y\rangle = 0$; $x \perp y$}\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.13} & \multicolumn{2}{l}{\textcolor{blue}{Pythagoras}: $||x \pm y||^2 = ||x||^2 + ||y||^2$, if $x \perp y$}\\
	\rule{0pt}{3ex}	
	Def. & \multicolumn{2}{l}{\textcolor{blue}{p-Norm}: $||x||_p :\equiv (|x_1|^p + ... + |x_n|^p)^{\frac{1}{p}}$}\\
\end{tabular}
\end{mainbox}

\begin{mainbox}{Outer Product and Projection}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rl}
	Def. & The \textcolor{blue}{outer product} is the matrix that is returned,\\
	& when multiplying the vectors x and y: $x\cdot y^H$\\
	& ($rank = 1$)\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.15} & The \textcolor{red}{orthogonal projection} $P_yx$ of $x$ on $y$\\
	& is given by: $P_yx :\equiv \frac{1}{||y||^2}yy^Hx$\\
	\rule{0pt}{3ex}
	Def. & The \textcolor{blue}{projection matrix} $P_y = \frac{1}{||y||^2}\cdot yy^H$\\
	& $P_y^H = P_y$ (Hermitian), $P_y^2 = P_y$ (Idempotent)\\
\end{tabular}

\end{mainbox}

\begin{mainbox}{Linear Transformations}
For all $x, \tilde{x} \in \mathbb{E}^n$ and $\gamma \in \mathbb{E}$:\\
$A(\gamma x + \tilde{x}) = \gamma (Ax) + (A\tilde{x})$
\smallskip\\
Def. \textcolor{red}{image of A}: $\;imA\;:\equiv\;\{Ax\in \mathbb{E}^m; x\in \mathbb{E}^n\}$\\
\end{mainbox}

\begin{mainbox}{Inverse}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rl}
	Def. & A nxn matrix A is \textcolor{blue}{invertible}, if there exists\\
	& a matrix $A^{-1}$, such that $A\cdot A^{-1} = I_n = A^{-1}A$.\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.17} & 4 equivalent statements:\\
	i) & A is invertible\\
	ii) & $\exists X$ such that $AX = I_n$\\
	iii) & X is definitive\\
	iv) & A is non-singular, i.e. rank A = n\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.18} & With two non-singular nxn matrices $A$ and $B$:\\
	i) & $A^{-1}$ is non-singular and $(A^{-1})^{-1} = A$\\
	ii) & $AB$ is non-singular and $(AB)^{-1} = B^{-1}A^{-1}$\\
	iii) & $A^H$ is non-singular and $(A^H)^{-1} = (A^{-1})^H$\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.19} & If $A$ is non-singular, $Ax = b$ has exactly one\\
	& solution for every b: $x = A^{-1}b$\\
\end{tabular}\\
\smallskip\\
\textcolor{red}{Find inverse $O(n^3)$}: $[\;A\;|\;I\;]\longrightarrow[\;I\;|\;A^{-1}\;]$\\
-> using elementary row operations\\
\smallskip\\
$A = \begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}$ and $detA \neq 0\;\Leftrightarrow A^{-1}=\frac{1}{ad-bc}\cdot \begin{bmatrix}
d & -b \\
-c & a \\
\end{bmatrix}$
\end{mainbox}

\begin{mainbox}{Orthogonal and Unitary Matrices}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rl}
	Def. & We call a matrix unitary or orthogonal, \\
	& if $A^HA = I_n$, $A^TA = I_n$ respectively.\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.20} & Let $A$ and $B$ be unitary:\\
	i) & $A$ is non-singular and $A^{-1} = A^H$\\
	ii) & $AA^H = I_n$\\
	iii) & $A^{-1}$ is unitary (/orthogonal)\\
	iv) & $AB$ is unitary (/orthogonal)\\
	\rule{0pt}{3ex}
	\textcolor{blue}{T 2.21} & A linear transformation defined by an orthog-\\
	& onal or unitary nxn matrix A is \textcolor{red}{length preserving} \\
	& (/isometric) and \textcolor{red}{angle preserving}:\\
	& $||Ax|| = ||x||$, $\langle Ax,Ay\rangle = \langle x,y\rangle$\\
\end{tabular}
\end{mainbox}

\begin{mainbox}{Examples of Important Matrices}
\textcolor{blue}{Rotationmatrices (orthogonal)}\\
$\begin{bmatrix}
cos(\varphi) & sin(\varphi) \\
-sin(\varphi) & cos(\varphi) \\
\end{bmatrix}$ or $\begin{bmatrix}
cos(\varphi) & 0 & sin(\varphi) & 0 \\
0 & 1 & 0 & 0 \\
-sin(\varphi) & 0 & cos(\varphi) & 0 \\
0 & 0 & 0 & 1 \\
\end{bmatrix}$
\\\smallskip\\
\textcolor{blue}{Permutationmatrices (orthogonal)}\\
$\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
\end{bmatrix}$ or
$\begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
\end{bmatrix}$
\\\smallskip\\
\textcolor{blue}{Blockmatrices}\\
$A = \left(\begin{array}{@{}c|c@{}}
  a_{11} & a_{12} \\
\hline
  a_{21} & a_{22}
\end{array}\right)$, if invertible $A^{-1} = \left(\begin{array}{@{}c|c@{}}
  a_{11}^{-1} & a_{12}^{-1} \\
\hline
  a_{21}^{-1} & a_{22}^{-1}
\end{array}\right)$
\end{mainbox}