\section{Matrices \& Vectors}
\begin{mainbox}{General}
$m$x$n$ Matrices have m rows and n columns.\\
The element $(i,j)$ can be denoted as $a_{i,j}$ or $(A)_{i,j}$\\
\textcolor{blue}{S 2.1}\\
\begin{tabular}{ll}
	$(\alpha\beta)A = \alpha(\beta A)$ & $(A+B)+C = A+(B+C)$ \\
	$(\alpha A)B = \alpha(AB)$ & $(AB)\cdot C = A\cdot (BC)$ \\
	$(\alpha + \beta)\cdot A = \alpha A + \beta A$ & $(A+B)\cdot C = AC + BC$ \\
	$\alpha (A+B) = \alpha A + \alpha B$ & $A\cdot (B+C) = AB+AC$ \\
	$A+B = B+A$ & \\
\end{tabular}\\
{\par\centering\danger in general$AB \neq BA$\\
If $AB = BA$ we say «A and B commute»\par}
\medskip

\begin{tabular}{ll}
	Def. & If $AB = O$, we call $A$ and $B$ \textcolor{blue}{divisors of zero}.\\
	Def. & A \textcolor{blue}{linear combination} of vectors $a_1 ... a_n$ is an\\
 	& expression of the following type:\\
 	& $\alpha_n\cdot a_n + ... + \alpha_1\cdot a_1$\\
	Def. & A matrix is \textcolor{blue}{symmetric} when $A^T = A$ and \\
	&  \textcolor{blue}{Hermitian} when $A^H = A$ (real diagonal).\\
	Def. & A matrix is \textcolor{blue}{skew-symmetric} when $A^T = -A$.\\
	& (zeros on diagonal) \\
\end{tabular}
\textcolor{blue}{S 2.6}\\
\begin{tabular}{ll}
	$(A^T)^T = A$ & $(\alpha A)^T = \alpha(A^T)$ \\
	$(AB)^T = B^TA^T$ & $(A+B)^T = A^T + B^T$ \\
\end{tabular}\\
\textcolor{blue}{S 2.7}\\
\begin{tabular}{l}
	If A, B symmetric: $AB = BA \Leftrightarrow AB$ symmetric\\
	For any A: $A^TA = AA^T$ (symmetric)\\
\end{tabular}


\end{mainbox}